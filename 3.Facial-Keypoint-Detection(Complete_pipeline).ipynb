{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.Facial-Keypoint-Detection(Complete_pipeline).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP97b073YcpOdcv+ZemHTD9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"86v4HjmjN5uG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HkBnmwjUOxR7","colab_type":"text"},"source":["## Face and Facial Keypoint detection\n"]},{"cell_type":"code","metadata":{"id":"MqpogzleO0Bb","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2YuqrfrOO5C4","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"h8sLLI-VO6zI","colab_type":"text"},"source":["#### Select an image \n"]},{"cell_type":"code","metadata":{"id":"8cFq4jnuO7lV","colab_type":"code","colab":{}},"source":["import cv2\n","# load in color image for face detection\n","image = cv2.imread('images/obamas.jpg')\n","\n","# switch red and blue color channels \n","# --> by default OpenCV assumes BLUE comes first, not RED as in many images\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","# plot the image\n","fig = plt.figure(figsize=(9,9))\n","plt.imshow(image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcKQ4rDwO_zC","colab_type":"text"},"source":["## Detect all faces in an image\n"]},{"cell_type":"code","metadata":{"id":"R7bOXysfO-gO","colab_type":"code","colab":{}},"source":["# load in a haar cascade classifier for detecting frontal faces\n","face_cascade = cv2.CascadeClassifier('detector_architectures/haarcascade_frontalface_default.xml')\n","\n","# run the detector\n","# the output here is an array of detections; the corners of each detection box\n","# if necessary, modify these parameters until you successfully identify every face in a given image\n","faces = face_cascade.detectMultiScale(image, 1.2, 2)\n","\n","# make a copy of the original image to plot detections on\n","image_with_detections = image.copy()\n","\n","# loop over the detected faces, mark the image where each face is found\n","for (x,y,w,h) in faces:\n","    # draw a rectangle around each detected face\n","    # you may also need to change the width of the rectangle drawn depending on image resolution\n","    cv2.rectangle(image_with_detections,(x,y),(x+w,y+h),(255,0,0),3) \n","\n","fig = plt.figure(figsize=(9,9))\n","\n","plt.imshow(image_with_detections)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8tB1RFd_PFxq","colab_type":"text"},"source":["## Loading in a trained model\n"]},{"cell_type":"code","metadata":{"id":"pUP97tSoO-i4","colab_type":"code","colab":{}},"source":["import torch\n","from models import Net\n","\n","net = Net()\n","\n","## TODO: load the best saved model parameters (by your path name)\n","## You'll need to un-comment the line below and add the correct name for *your* saved model\n","net.load_state_dict(torch.load('saved_models/keypoints_model_1.pt'))\n","# net.load_state_dict(torch.load('saved_models/Net.pt'))\n","\n","## print out your net and prepare it for testing (uncomment the line below)\n","net.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oo8055VZPKaw","colab_type":"text"},"source":["## Keypoint detection\n","### TODO: Transform each detected face into an input Tensor\n","### TODO: Detect and display the predicted keypoints\n"]},{"cell_type":"code","metadata":{"id":"HncPsHtSO-k2","colab_type":"code","colab":{}},"source":["def show_all_keypoints(image, keypoints):\n","    \"\"\"\n","    Visuzlizing the image and the keypoints on it.\n","    \"\"\"\n","    plt.figure(figsize=(5,5))\n","    \n","    keypoints = keypoints.data.numpy()\n","    keypoints = keypoints * 60.0 + 96 # Becuase of normalization, keypoints won't be placed if they won't reutrn to values before noramlization \n","    keypoints = np.reshape(keypoints, (68, -1)) # reshape to 2 X 68 keypoint for the fase\n","\n","    image = image.numpy()   \n","    image = np.transpose(image, (1, 2, 0))  # Convert to numpy image shape (H x W x C)\n","    image = np.squeeze(image)\n","    plt.imshow(image, cmap='gray')\n","    plt.scatter(keypoints[:, 0], keypoints[:, 1], s=40, marker='.', c='m')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVMEop-6PX0R","colab_type":"code","colab":{}},"source":["from torch.autograd import Variable\n","\n","image_copy = np.copy(image)\n","\n","# loop over the detected faces from your haar cascade\n","for (x,y,w,h) in faces:\n","\n","    # Select the region of interest that is the face in the image \n","    roi = image_copy[y:y + int(1.5 * h), x - int(0.4 * w):x + int(1.1 * w)]\n","    #plt.imshow(roi)\n","    \n","    ## TODO: Convert the face region from RGB to grayscale\n","    roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n","    #plt.imshow(roi, cmap = 'gray')\n","    \n","    ## TODO: Normalize the grayscale image so that its color range falls in [0,1] instead of [0,255]\n","    roi = roi / 255.\n","    #plt.imshow(roi, cmap = 'gray')\n","    \n","    ## TODO: Rescale the detected face to be the expected square size for your CNN (224x224, suggested)\n","    roi = cv2.resize(roi, (224, 224))\n","    #plt.imshow(roi, cmap = 'gray')\n","    \n","    ## TODO: Reshape the numpy image shape (H x W x C) into a torch image shape (C x H x W)\n","    roi = np.expand_dims(roi, 0)\n","    roi = np.expand_dims(roi, 0) # (1, 1, 224, 224)\n","    # roi = np.reshape(roi, (1, 1, 224, 224)) # Option 2\n","    #print(roi.shape)\n","\n","    ## TODO: Make facial keypoint predictions using your loaded, trained network \n","    ## perform a forward pass to get the predicted facial keypoints\n","    roi_torch = Variable(torch.from_numpy(roi)) # Converting numpy to torch variable\n","    #print(roi_torch.shape)\n","    roi_torch = roi_torch.type(torch.FloatTensor)\n","    keypoints = net(roi_torch) # Forward pass\n","    \n","    ## TODO: Display each detected face and the corresponding keypoints        \n","    show_all_keypoints(roi_torch.squeeze(0), keypoints)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vh8LYyriPbR0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oIAmx5NPbV4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aycNZKLNPbYr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WY7idSakPbap","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"53WT1wspPX2k","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}